from immunova.data.panel import ChannelMap
from immunova.data.gating import Gate
from bson.binary import Binary
import numpy as np
import mongoengine
import pickle


def generate_sample(data, n) -> np.array:
    if n < data.shape[0]:
        idx = np.random.randint(data.shape[0], size=n)
        return data[idx, :]
    return data


class ClusteringDefinition(mongoengine.Document):
    """
    Defines the methodology and parameters of clustering to apply to an FCS File Group, or in the case of
    meta-clustering, a collection of FCS File Groups from the same FCS Experiment

    Parameters
    clustering_uid: unique identifier
    method: type of clustering performed, either PhenoGraph or FlowSOM
    parameters: parameters passed to clustering algorithm
    features: list of channels/markers that clustering is performed on
    transform_method: type of transformation to be applied to data prior to clustering
    root_population: population that clustering is performed on (default = 'root')
    cluster_prefix: a prefix to add to the name of each resulting cluster
    meta_clustering: refers to whether the clustering is 'meta-clustering'
    """
    clustering_uid = mongoengine.StringField(required=True, unique=True)
    method = mongoengine.StringField(required=True, choices=['PhenoGraph', 'FlowSOM'])
    parameters = mongoengine.ListField(required=True)
    features = mongoengine.ListField(required=True)
    transform_method = mongoengine.StringField(required=False, default='logicle')
    root_population = mongoengine.StringField(required=True, default='root')
    cluster_prefix = mongoengine.StringField(required=True, default='cluster')

    meta = {
        'db_alias': 'core',
        'collection': 'cluster_definitions'
    }


class Cluster(mongoengine.EmbeddedDocument):
    """
    Represents a single cluster generated by a clustering experiment on a single file

    Attributes:
        cluster_id - name associated to cluster
        index - index of cell events associated to cluster
    """
    cluster_id = mongoengine.StringField(required=True)
    index = mongoengine.FileField(db_alias='core', collection_name='cluster_indexes')
    n_events = mongoengine.IntField(required=True)
    prop_of_root = mongoengine.FloatField(required=True)
    cluster_experiment = mongoengine.ReferenceField(ClusteringDefinition)

    def save_index(self, data: np.array) -> None:
        if self.index:
            self.index.replace(Binary(pickle.dumps(data, protocol=2)))
        else:
            self.index.new_file()
            self.index.write(Binary(pickle.dumps(data, protocol=2)))
            self.index.close()

    def load_index(self) -> np.array:
        return pickle.loads(bytes(self.index.read()))


class Population(mongoengine.EmbeddedDocument):
    """
    Embedded document -> FileGroup
    Cached populations; stores the index of events associated to a population
    for quick loading.

    Attributes:
        population_name - name of population
        index - numpy array storing index of events that belong to population
        prop_of_parent - proportion of cells as a percentage of parent population
        prop_of_total - proportion of cells as a percentage of all events
        warnings - list of warnings associated to population
        parent - name of parent population
        children - list of child populations (list of strings)
        geom - list of key value pairs (tuples; (key, value)) for defining geom of population e.g.
        the definition for an ellipse that 'captures' the population
    Methods:
        save_index - given a new numpy array of index values, serialise and commit data to database
        load_index - retrieve the index values for the given population
        to_python - generate a python dictionary object for this population
    """
    population_name = mongoengine.StringField()
    index = mongoengine.FileField(db_alias='core', collection_name='population_indexes')
    parent = mongoengine.StringField()
    prop_of_parent = mongoengine.FloatField()
    prop_of_total = mongoengine.FloatField()
    warnings = mongoengine.ListField()
    geom = mongoengine.ListField()
    clustering = mongoengine.EmbeddedDocumentListField(Cluster)
    clusters = mongoengine.ListField()

    def save_index(self, data: np.array) -> None:
        if self.index:
            self.index.replace(Binary(pickle.dumps(data, protocol=2)))
        else:
            self.index.new_file()
            self.index.write(Binary(pickle.dumps(data, protocol=2)))
            self.index.close()

    def load_index(self) -> np.array:
        return pickle.loads(bytes(self.index.read()))

    def to_python(self) -> dict:
        geom = {k: v for k, v in self.geom}
        population = dict(name=self.population_name, prop_of_parent=self.prop_of_parent,
                          prop_of_total=self.prop_of_total, warnings=self.warnings, geom=geom,
                          parent=self.parent, index=self.load_index())
        return population

    def list_clustering_experiments(self):
        return [c.cluster_experiment.clustering_uid for c in self.clustering]

    def pull_clusters(self, clustering_uid: str):
        if clustering_uid not in self.list_clustering_experiments():
            raise ValueError(f'Error: a clustering experiment with UID {clustering_uid} does not exist')
        return [c for c in self.clustering if c.cluster_experiment.clustering_uid == clustering_uid]

    def delete_clusters(self, clustering_uid: str):
        if clustering_uid not in self.list_clustering_experiments():
            raise ValueError(f'Error: a clustering experiment with UID {clustering_uid} does not exist')
        self.clustering = [c for c in self.clustering if c.cluster_experiment.clustering_uid != clustering_uid]


class Normalisation(mongoengine.EmbeddedDocument):
    data = mongoengine.FileField(db_alias='core', collection_name='fcs_file_norm')
    root_population = mongoengine.StringField()
    method = mongoengine.StringField()

    def norm_data(self, sample: int or None = None) -> np.array:
        """
        Load normalised data
        :param sample: int value; produces a sample of given value
        :return:  Numpy array of events data (normalised)
        """
        data = pickle.loads(self.data.read())
        if sample:
            return generate_sample(data, sample)
        return data

    def put(self, data: np.array, root_population: str, method: str) -> None:
        """
        Save events data to database
        :param data: numpy array of events data
        :return: None
        """
        if self.data:
            self.data.replace(Binary(pickle.dumps(data, protocol=2)))
        else:
            self.data.new_file()
            self.data.write(Binary(pickle.dumps(data, protocol=2)))
            self.data.close()
        self.root_population = root_population
        self.method = method


class File(mongoengine.EmbeddedDocument):
    """
    Embedded document -> FileGroup
    Document representation of a single FCS file.

    Attributes:
        file_id - unique identifier for fcs file
        file_type - one of either 'complete' or 'control'; signifies the type of data stored
        data - numpy array of fcs events data
        norm - numpy array of normalised fcs events data
        compensated - boolean value, if True then data have been compensated
        channel_mappings - list of standarised channel/marker mappings (corresponds to column names of underlying data)

    Methods:
        raw_data - loads raw data returning a numpy array
        norm_data - loads normalised data returning a numpy array
        put - given a numpy array, data is serialised and stored
        data_from_file - pull data associated to this File object
        as_dataframe - convert matrix data from File object into a pandas dataframe
    """
    file_id = mongoengine.StringField(required=True)
    file_type = mongoengine.StringField(default='complete')
    data = mongoengine.FileField(db_alias='core', collection_name='fcs_file_data')
    norm = mongoengine.EmbeddedDocumentField(Normalisation)
    compensated = mongoengine.BooleanField(default=False)
    channel_mappings = mongoengine.EmbeddedDocumentListField(ChannelMap)

    def raw_data(self, sample: int or None = None) -> np.array:
        """
        Load raw data
        :param sample: int value; produces a sample of given value
        :return:  Numpy array of events data (raw)
        """
        data = pickle.loads(self.data.read())
        if sample:
            return generate_sample(data, sample)
        return data

    def put(self, data: np.array) -> None:
        """
        Save events data to database
        :param data: numpy array of events data
        :param typ: type of data; either `data` (raw) or `norm` (normalised)
        :return: None
        """
        if self.data:
            self.data.replace(Binary(pickle.dumps(data, protocol=2)))
        else:
            self.data.new_file()
            self.data.write(Binary(pickle.dumps(data, protocol=2)))
            self.data.close()


class FileGroup(mongoengine.Document):
    """
    Document representation of a file group; a selection of related fcs files (e.g. a sample and it's associated
    controls)

    Attributes:
        primary_id - unique ID to associate to group
        files - list of File objects
        flags - warnings associated to file group
        notes - additional free text
        populations - populations derived from this file group
        gates - gate objects that have been applied to this file group
    """
    primary_id = mongoengine.StringField(required=True)
    files = mongoengine.EmbeddedDocumentListField(File)
    flags = mongoengine.StringField(required=False)
    notes = mongoengine.StringField(required=False),
    collection_datetime = mongoengine.DateTimeField(required=False)
    processing_datetime = mongoengine.DateTimeField(required=False)
    populations = mongoengine.EmbeddedDocumentListField(Population)
    gates = mongoengine.EmbeddedDocumentListField(Gate)
    meta = {
        'db_alias': 'core',
        'collection': 'fcs_files'
    }


